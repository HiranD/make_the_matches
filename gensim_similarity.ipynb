{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hiran Dissanayake\\.conda\\envs\\nongpu\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from  gensim.similarities.docsim import Similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from gensim import corpora\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DALTIX_ID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43823f3f6826dcfd1f14b5898d742a1ead54937001f980...</td>\n",
       "      <td>velgenreiniger car bike krcher geschikt remspo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2258f16fa7ff7aab35c4534ac645017637d072f2fee9cc...</td>\n",
       "      <td>matte muurverf originals potloodgrijs levis ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69ec8d4f776200897422a4b8f93d3416a36781fe110d75...</td>\n",
       "      <td>vlakdraad nieten oorspronkelijk ontworpen blac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f03ef881a1d1934c62b9db6b4403a59ae34de96148f362...</td>\n",
       "      <td>toiletmeubel fabulous 40 meest verkochte badme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaff0aa6db24814ad25d5cb410ded08361ab32bcb953e1...</td>\n",
       "      <td>pickup pictogram zelfklevend weerbestendig een...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           DALTIX_ID  \\\n",
       "0  43823f3f6826dcfd1f14b5898d742a1ead54937001f980...   \n",
       "1  2258f16fa7ff7aab35c4534ac645017637d072f2fee9cc...   \n",
       "2  69ec8d4f776200897422a4b8f93d3416a36781fe110d75...   \n",
       "3  f03ef881a1d1934c62b9db6b4403a59ae34de96148f362...   \n",
       "4  aaff0aa6db24814ad25d5cb410ded08361ab32bcb953e1...   \n",
       "\n",
       "                                                text  \n",
       "0  velgenreiniger car bike krcher geschikt remspo...  \n",
       "1  matte muurverf originals potloodgrijs levis ge...  \n",
       "2  vlakdraad nieten oorspronkelijk ontworpen blac...  \n",
       "3  toiletmeubel fabulous 40 meest verkochte badme...  \n",
       "4  pickup pictogram zelfklevend weerbestendig een...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [[word for word in row['text'].split()] for index, row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [[token for token in text if frequency[token] > 1]for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(77214 unique tokens: ['0,5', '500.0', 'accessoires', 'af', 'alle']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.save('daltix.dict')\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora.MmCorpus.serialize('daltix.mm', corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = Similarity(\"daltix.sim.index\", corpus, num_features=len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                       | 0/101781 [00:00<?, ?it/s]C:\\Users\\Hiran Dissanayake\\.conda\\envs\\nongpu\\lib\\site-packages\\gensim\\similarities\\docsim.py:517: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  result = numpy.hstack(shard_results)\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 101781/101781 [21:04<00:00, 80.48it/s]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "results = []\n",
    "for similarities in tqdm(index):\n",
    "#     print(similarities.argsort()[-3:][::-1], i)\n",
    "    arr = similarities.argsort()[-3:][::-1]\n",
    "    indx = np.argwhere(arr==i)\n",
    "    arr = np.delete(arr, indx)\n",
    "#     print(i,arr[0],similarities[arr[0]])\n",
    "    results.append((i,arr[0],similarities[arr[0]]))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 101781/101781 [00:25<00:00, 3921.03it/s]\n"
     ]
    }
   ],
   "source": [
    "results_ = []\n",
    "for (i,j,k) in tqdm(results):\n",
    "#     print(i,j,k)\n",
    "    results_.append((df.iloc[i]['DALTIX_ID'],df.iloc[j]['DALTIX_ID'],k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results_, columns=['daltix_id_1', 'daltix_id_2', 'similarity']).to_csv(\"docsim_df.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nongpu",
   "language": "python",
   "name": "nongpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
